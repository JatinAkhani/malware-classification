{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gx7MuyfdSXdk"
   },
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import os \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-8Kx6c9zPlp"
   },
   "source": [
    "# Fetch data from Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_mCmajMRYJI",
    "outputId": "4b8498fe-52fc-414d-db07-e596b92c7b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-12 16:44:09--  https://storage.googleapis.com/kagglesdsdata/competitions/4117/46665/train.7z?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1652633003&Signature=KU1y8Vd1hV7uR3FV2WTf6U7TkBnjYcNG7miAO0yZeKwxID1UU9C2EVPEcf7SFjzq9vB2gy%2BOfodUtuGrcP%2FBzuygjHfDNv9EUFQKcnd8s4KlBmB1ORRQbuzA3PlXrbYHY4BpvdHllE7NJY7u14s1nxf9CfBXtlEt%2BNOjJcCL%2BNDoYEEhGIjuHTzX30ra50X05A2ROUIgt7BjAqD18ott5kxILvSIftsC0gadKo%2F14eACamoMqBPcdJE5yMtNXIpSUdVAeFjClmWomdpDddm6uFqQ3sI5quEKGqzh0qZP94LtyecVbPrU76t6qMdH7VuNgHarpz22sn8euFnzr70YIg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.7z\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 173.194.202.128, 74.125.199.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18810691091 (18G) [application/x-7z-compressed]\n",
      "Saving to: ‘train.7z’\n",
      "\n",
      "train.7z            100%[===================>]  17.52G   151MB/s    in 1m 52s  \n",
      "\n",
      "2022-05-12 16:46:02 (160 MB/s) - ‘train.7z’ saved [18810691091/18810691091]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download link - https://www.kaggle.com/competitions/malware-classification/data?select=train.7z\n",
    "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kagglesdsdata/competitions/4117/46665/train.7z?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1652633003&Signature=KU1y8Vd1hV7uR3FV2WTf6U7TkBnjYcNG7miAO0yZeKwxID1UU9C2EVPEcf7SFjzq9vB2gy%2BOfodUtuGrcP%2FBzuygjHfDNv9EUFQKcnd8s4KlBmB1ORRQbuzA3PlXrbYHY4BpvdHllE7NJY7u14s1nxf9CfBXtlEt%2BNOjJcCL%2BNDoYEEhGIjuHTzX30ra50X05A2ROUIgt7BjAqD18ott5kxILvSIftsC0gadKo%2F14eACamoMqBPcdJE5yMtNXIpSUdVAeFjClmWomdpDddm6uFqQ3sI5quEKGqzh0qZP94LtyecVbPrU76t6qMdH7VuNgHarpz22sn8euFnzr70YIg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.7z\" -c -O 'train.7z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJ-DXER01EmA",
    "outputId": "8db3ea09-da1d-4cfd-d09d-eb902e175945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py7zr in /opt/conda/lib/python3.7/site-packages (0.18.5)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.7/site-packages (from py7zr) (0.2.3)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in /opt/conda/lib/python3.7/site-packages (from py7zr) (0.15.2)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from py7zr) (4.11.3)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /opt/conda/lib/python3.7/site-packages (from py7zr) (1.0.9)\n",
      "Requirement already satisfied: zipfile-deflate64>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from py7zr) (0.2.0)\n",
      "Requirement already satisfied: pyppmd<0.19.0,>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from py7zr) (0.18.2)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.7/site-packages (from py7zr) (1.6.4)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from py7zr) (3.14.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from py7zr) (5.9.0)\n",
      "Requirement already satisfied: pybcj>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from py7zr) (0.5.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->py7zr) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B16FPWF41EmB",
    "outputId": "073ece3f-28a5-45bb-a4eb-db7f600282cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21737\n"
     ]
    }
   ],
   "source": [
    "import py7zr\n",
    "with py7zr.SevenZipFile('train.7z', mode='r') as z:\n",
    "    data = z.getnames()\n",
    "\n",
    "#check the total number of files in archive\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uigbJLsSEbL"
   },
   "outputs": [],
   "source": [
    "byte_files_list = []\n",
    "asm_files_list = []\n",
    "for i in data:\n",
    "    if i.endswith('bytes'):\n",
    "        byte_files_list.append(i)\n",
    "    elif i.endswith('asm'):\n",
    "        asm_files_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFjLf5RUSGu-",
    "outputId": "bba12cb2-b7b1-4ae2-bca4-de0f4edf7d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in bytes format: 10868 \n",
      "Total files in asm format: 10868\n"
     ]
    }
   ],
   "source": [
    "print('Total files in bytes format:', len(byte_files_list),'\\nTotal files in asm format:', len(asm_files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHyaVh-ZSJd9",
    "outputId": "0104ac80-9060-429a-9ad7-61761b489d0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('train/01azqd4InC7m9JpocGv5.bytes', 'train/01azqd4InC7m9JpocGv5.asm')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check how the file names look\n",
    "byte_files_list[0], asm_files_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mY7mVQH2SLgH"
   },
   "outputs": [],
   "source": [
    "#lets only store the filename in list and remove rest of unecessary information\n",
    "for i in range(0, len(byte_files_list)):\n",
    "    byte_files_list[i] = byte_files_list[i].split()[-1].replace('train/','')\n",
    "\n",
    "for i in range(0, len(asm_files_list)):\n",
    "    asm_files_list[i] = asm_files_list[i].split()[-1].replace('train/','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWgn_1sFSRHG",
    "outputId": "9cebb3ef-4b18-4497-e730-f7c37b069656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('01azqd4InC7m9JpocGv5.bytes', '01azqd4InC7m9JpocGv5.asm')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check how the file names look now \n",
    "byte_files_list[0], asm_files_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsDvORxS1EmJ",
    "outputId": "38d07afa-e57a-457f-f6da-1fa4bdcfa577"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if asm_files_list and byte_files_list are in same order\n",
    "list(map(lambda x: x.split('.')[0], byte_files_list))== list(map(lambda x: x.split('.')[0], asm_files_list)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4kowQEZGXCK"
   },
   "source": [
    "# Extracting .bytes files to 'bytefiles' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T86W_gKhPqsc"
   },
   "outputs": [],
   "source": [
    "#create a folder \n",
    "!mkdir bytefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAybMlft1EmN"
   },
   "outputs": [],
   "source": [
    "#extract all bytes files to bytefiles folder\n",
    "with py7zr.SevenZipFile('train.7z', 'r') as zf:\n",
    "    byte_file_paths = [x for x in data if x.endswith('.bytes')]\n",
    "    zf.extract(path='bytefiles', targets = byte_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bS2st4sgZn6"
   },
   "source": [
    "# Converting content of all .bytes file to vector one at a time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZ2hP1zGglwk"
   },
   "source": [
    "### Applying Count Vectorizer to get bigram count vectors\n",
    "1. Here we feed our own vocabulary to the CountVectorizer to avoid calling the fit method which runs through all the documents in the corpus to find the unique bigrams which requires the corpus to be loaded in the memory.\n",
    "2. Since our corpus is huge we avoid that by providing our vocabulary directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1sWSsj-70Z3"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZsKArnuYfJn"
   },
   "outputs": [],
   "source": [
    "#the below function inputs unigrams and returns a list of bigrams (i.e. all possible unigram combinations)\n",
    "def generate_bigrams(ls):\n",
    "    ls = ls.split(',')\n",
    "    bigrams = [\" \".join((i,j)) for i in ls for j in ls]\n",
    "    return bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DcaJHio1EmP"
   },
   "outputs": [],
   "source": [
    "ls = '00,01,02,03,04,05,06,07,08,09,0a,0b,0c,0d,0e,0f,10,11,12,13,14,15,16,17,18,19,1a,1b,1c,1d,1e,1f,20,21,22,23,24,25,26,27,28,29,2a,2b,2c,2d,2e,2f,30,31,32,33,34,35,36,37,38,39,3a,3b,3c,3d,3e,3f,40,41,42,43,44,45,46,47,48,49,4a,4b,4c,4d,4e,4f,50,51,52,53,54,55,56,57,58,59,5a,5b,5c,5d,5e,5f,60,61,62,63,64,65,66,67,68,69,6a,6b,6c,6d,6e,6f,70,71,72,73,74,75,76,77,78,79,7a,7b,7c,7d,7e,7f,80,81,82,83,84,85,86,87,88,89,8a,8b,8c,8d,8e,8f,90,91,92,93,94,95,96,97,98,99,9a,9b,9c,9d,9e,9f,a0,a1,a2,a3,a4,a5,a6,a7,a8,a9,aa,ab,ac,ad,ae,af,b0,b1,b2,b3,b4,b5,b6,b7,b8,b9,ba,bb,bc,bd,be,bf,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9,ca,cb,cc,cd,ce,cf,d0,d1,d2,d3,d4,d5,d6,d7,d8,d9,da,db,dc,dd,de,df,e0,e1,e2,e3,e4,e5,e6,e7,e8,e9,ea,eb,ec,ed,ee,ef,f0,f1,f2,f3,f4,f5,f6,f7,f8,f9,fa,fb,fc,fd,fe,ff,??'\n",
    "bigram_vocab = generate_bigrams(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OyxwEzJQjZh",
    "outputId": "f3cf8b6d-7596-40dd-9f44-d34541c7bbf6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 10868/10868 [4:03:55<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "folder_path_byte = 'bytefiles/train/'\n",
    "\n",
    "#since we have the bigrams list we do not need to learn the bigrams by fitting the vectorizer to documents \n",
    "#we pre feed the bigrams list as vocabulary to the vectorizer, also this method is more memory efficient.\n",
    "bow = CountVectorizer(ngram_range=(2,2), vocabulary=bigram_vocab)  \n",
    "bow_vec_list = [] #vectorizer returns a sparse representation of counts for each document, store the sparse matrices in this list\n",
    "\n",
    "#use the byte_files_list to obtain count vectors in that order\n",
    "#for each name/id in byte_files_list, access the actual byte file from the bytefiles folder\n",
    "#read the content of the byte file store in a string\n",
    "#then feed the string to the vectorizer to obtain a count vector (in csr sparse matrix form)\n",
    "#append the matrix to bow_vec_list, carry out the process for each byte file\n",
    "#also simultaneaously remove/delete the byte file from the bytefiles folder once the count vector is obtained, to free up space\n",
    "for b_file in tqdm(byte_files_list):\n",
    "    \n",
    "    to_string = ''\n",
    "\n",
    "    with open(folder_path_byte+b_file, 'rb') as fb:  \n",
    "        for line in fb: #read the byte file line by line \n",
    "            a = str(line).rstrip().split()[1:] #convert the line to string and strip the spaces at right end, get the list of words in line (note: first word in each line is address which is unecessary so we ignore it using [1:])\n",
    "      \n",
    "            b = ' '.join(a) #join all the words again with a space in between\n",
    "            b = re.sub('[^A-Z0-9 ]', '', b) #use regex to only retain spaces, A-Z, 0-9 and replace rest with empty string \n",
    "            b = b+'\\n' #add a newline character at the end of line\n",
    "      \n",
    "            to_string += b #write the entire byte file into 'to_string' one line at a time \n",
    "    \n",
    "    to_bow_vec = bow.transform([to_string])\n",
    "    bow_vec_list.append(to_bow_vec)\n",
    "\n",
    "    os.remove(folder_path_byte+b_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCWsr-6qOatv"
   },
   "outputs": [],
   "source": [
    "#remove the bytefiles folder\n",
    "import shutil\n",
    "shutil.rmtree('bytefiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4j-3eXZG8wk"
   },
   "source": [
    "# Stacking all the count vectors to obtain the final feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXw5Irc11EmR"
   },
   "source": [
    "Next, we vertically stack all the matrices.\n",
    "\n",
    "Note: vstack operations are memory expensive and the size of our matrices are considerably large so avoid using colab because there are high chances that the RAM overshoots in colab and it restarts the session resulting in loss of all the variables and progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pblCN3D71EmR"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tfmpk2R1EmR"
   },
   "outputs": [],
   "source": [
    "#creating a copy of bow_vec_list, just to be safe\n",
    "bow_vec_ls_cpy = bow_vec_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hp9jVffc1EmS"
   },
   "outputs": [],
   "source": [
    "#vstack is a memory costly operation, to avoid overflow of memory first vertically stack small batches of sparse matrics and store them in a list\n",
    "ln = len(bow_vec_ls_cpy)\n",
    "batch = 500\n",
    "rem = ln%batch\n",
    "perfectly_div = ln-rem\n",
    "\n",
    "blocks = []\n",
    "\n",
    "for i in range(0,perfectly_div,batch):\n",
    "    blocks.append(vstack(bow_vec_ls_cpy[i:i+batch], format='csr'))\n",
    "\n",
    "if rem!=0:\n",
    "    blocks.append(vstack(bow_vec_ls_cpy[perfectly_div:], format='csr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IhS7FxE1EmS"
   },
   "outputs": [],
   "source": [
    "#finally vertically stack all them blocks together \n",
    "final_bigram_feat_mat = vstack(blocks, format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5if4-VRZ1EmS",
    "outputId": "062c2189-7930-41f3-f996-4af5034e0075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10868, 66049)\n"
     ]
    }
   ],
   "source": [
    "#lets check the shape of our final matrix\n",
    "print(final_bigram_feat_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHKnG7cK_Uo4"
   },
   "outputs": [],
   "source": [
    "#save feature matrix\n",
    "#note: this takes ~1GB sapce in your drive and will take some time to save\n",
    "scipy.sparse.save_npz('saved files/bytes_bigram_features.npz', final_bigram_feat_mat)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Microsoft_Malware_Bigram_Feature_Extractionipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
